{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python\n",
        "#%pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qprz7JPRTDL",
        "outputId": "71c3d0d0-3f39-462b-927f-c34070d960b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.12.0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"vencerlanz09/agricultural-pests-image-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# List the contents to understand dataset structure\n",
        "print(\"\\nDataset structure:\")\n",
        "for root, dirs, files in os.walk(path):\n",
        "    level = root.replace(path, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:3]:  # Show first 5 files in each directory\n",
        "        print(f'{subindent}{file}')\n",
        "    if len(files) > 3:\n",
        "        print(f'{subindent}... and {len(files)-3} more files')\n",
        "\n",
        "# Core deep learning libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetV2B0, EfficientNetV2B1\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "\n",
        "# Data manipulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
        "print(f\"Available GPUs: {len(tf.config.list_physical_devices('GPU'))}\")\n",
        "\n",
        "# Check if GPU is available in Colab\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"üöÄ GPU acceleration available!\")\n",
        "    print(\"GPU Details:\", tf.config.list_physical_devices('GPU')[0])\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Running on CPU - consider enabling GPU in Colab Runtime menu\")\n",
        "\n",
        "# Global dataset path for easy access\n",
        "DATASET_PATH = path\n",
        "\n",
        "print(\"\\nüåæ Agricultural Computer Vision Setup Complete!\")\n",
        "print(f\"üìÅ Dataset location: {DATASET_PATH}\")"
      ],
      "metadata": {
        "id": "meBvbfBHSTBQ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3126129-ca04-47dd-821f-5b580d3ed429"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/agricultural-pests-image-dataset\n",
            "\n",
            "Dataset structure:\n",
            "agricultural-pests-image-dataset/\n",
            "  beetle/\n",
            "    beetle (219).jpg\n",
            "    beetle (285).jpg\n",
            "    beetle (124).jpg\n",
            "    ... and 413 more files\n",
            "  grasshopper/\n",
            "    grasshopper (469).jpg\n",
            "    grasshopper (480).jpg\n",
            "    grasshopper (244).jpg\n",
            "    ... and 482 more files\n",
            "  earthworms/\n",
            "    earthworms (8).jpg\n",
            "    earthworms (166).jpg\n",
            "    earthworms (182).jpg\n",
            "    ... and 320 more files\n",
            "  ants/\n",
            "    ants (242).jpg\n",
            "    ants (414).jpg\n",
            "    ants (321).jpg\n",
            "    ... and 496 more files\n",
            "  earwig/\n",
            "    earwig (202).jpg\n",
            "    earwig (384).jpg\n",
            "    earwig (195).jpg\n",
            "    ... and 463 more files\n",
            "  snail/\n",
            "    snail (253).jpg\n",
            "    snail (117).jpg\n",
            "    snail (350).jpg\n",
            "    ... and 497 more files\n",
            "  catterpillar/\n",
            "    catterpillar (153).jpg\n",
            "    catterpillar (44).jpg\n",
            "    catterpillar (250).jpg\n",
            "    ... and 431 more files\n",
            "  weevil/\n",
            "    Weevil (72).jpg\n",
            "    Weevil (293).jpg\n",
            "    Weevil (456).jpg\n",
            "    ... and 482 more files\n",
            "  bees/\n",
            "    bees (375).jpg\n",
            "    bees (390).jpg\n",
            "    bees (379).jpg\n",
            "    ... and 497 more files\n",
            "  moth/\n",
            "    moth (128).jpg\n",
            "    moth (168).jpg\n",
            "    moth (298).jpg\n",
            "    ... and 494 more files\n",
            "  wasp/\n",
            "    wasp (623).jpg\n",
            "    wasp (552).jpg\n",
            "    wasp (878).jpg\n",
            "    ... and 495 more files\n",
            "  slug/\n",
            "    slug (130).jpg\n",
            "    slug (350).jpg\n",
            "    slug (63).jpg\n",
            "    ... and 388 more files\n",
            "\n",
            "TensorFlow version: 2.19.0\n",
            "Available GPUs: 0\n",
            "‚ö†Ô∏è Running on CPU - consider enabling GPU in Colab Runtime menu\n",
            "\n",
            "üåæ Agricultural Computer Vision Setup Complete!\n",
            "üìÅ Dataset location: /kaggle/input/agricultural-pests-image-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset configuration for agricultural pest management\n",
        "IMG_SIZE = 224  # EfficientNetV2 optimal input size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Explore the actual dataset structure\n",
        "def explore_dataset_structure(dataset_path):\n",
        "    \"\"\"\n",
        "    Explore the downloaded Kaggle dataset structure and identify class directories.\n",
        "    \"\"\"\n",
        "    print(\"üîç EXPLORING ACTUAL DATASET STRUCTURE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Find all subdirectories which represent classes\n",
        "    class_dirs = [os.path.join(dataset_path, d) for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "\n",
        "    print(f\"Found potential class directories:\")\n",
        "    for class_dir in class_dirs:\n",
        "        print(f\"  - {os.path.basename(class_dir)}\")\n",
        "\n",
        "    # Count classes and images\n",
        "    classes = [os.path.basename(d) for d in class_dirs]\n",
        "    print(f\"\\nClasses found: {len(classes)}\")\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            print(f\"  - {class_name}: {num_images} images\")\n",
        "\n",
        "    # In this dataset structure, the main dataset_path is the 'train' equivalent\n",
        "    # and we will use validation_split for validation and potentially a test split later.\n",
        "    return dataset_path, None, None # Return dataset_path as train_dir and None for test/val\n",
        "\n",
        "# Explore the dataset\n",
        "train_dir, test_dir, val_dir = explore_dataset_structure(DATASET_PATH)\n",
        "\n",
        "def create_agricultural_data_generators(main_dir, test_dir=None, validation_split=0.2):\n",
        "    \"\"\"\n",
        "    Create data generators optimized for agricultural images using the actual dataset structure\n",
        "    where classes are directly in the main_dir.\n",
        "    \"\"\"\n",
        "\n",
        "    if not main_dir or not os.path.exists(main_dir):\n",
        "        print(\"‚ùå Main dataset directory not found. Please check dataset structure.\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Get number of classes from the main directory\n",
        "    classes = [d for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))]\n",
        "    num_classes = len(classes)\n",
        "\n",
        "    print(f\"üåæ AGRICULTURAL DATA GENERATORS SETUP\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"üìÅ Main dataset directory: {main_dir}\")\n",
        "    print(f\"üè∑Ô∏è Classes: {classes}\")\n",
        "    print(f\"üìä Number of classes: {num_classes}\")\n",
        "    print(f\"üìê Using validation_split={validation_split} from main directory.\")\n",
        "\n",
        "\n",
        "    # Training data augmentation - crucial for outdoor agricultural images\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,  # EfficientNetV2 preprocessing\n",
        "        rotation_range=40,          # Pests can appear at any angle\n",
        "        width_shift_range=0.3,      # Account for pest movement\n",
        "        height_shift_range=0.3,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.3,             # Pests at different distances\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,         # Pests can be upside down\n",
        "        brightness_range=[0.6, 1.4], # Outdoor lighting variations\n",
        "        fill_mode='nearest',\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "\n",
        "    # Validation data - no augmentation, only preprocessing\n",
        "    # Use the same datagen object as train for validation split\n",
        "    val_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        validation_split=validation_split\n",
        "    )\n",
        "\n",
        "    # Test data generator (if a separate test dir exists, which is not the case here)\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Create train generator\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        main_dir,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        shuffle=True,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    # Create validation generator\n",
        "    validation_generator = val_datagen.flow_from_directory(\n",
        "        main_dir,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        subset='validation',\n",
        "        shuffle=False, # No shuffling for validation\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    # Create test generator if test directory exists (not applicable in this dataset)\n",
        "    test_generator = None\n",
        "    if test_dir and os.path.exists(test_dir):\n",
        "         test_generator = test_datagen.flow_from_directory(\n",
        "            test_dir,\n",
        "            target_size=(IMG_SIZE, IMG_SIZE),\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='categorical',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "\n",
        "    # Update global NUM_CLASSES\n",
        "    global NUM_CLASSES\n",
        "    NUM_CLASSES = num_classes\n",
        "\n",
        "    print(f\"\\nüìà DATA GENERATOR SUMMARY:\")\n",
        "    print(f\"  Training samples: {train_generator.samples}\")\n",
        "    print(f\"  Validation samples: {validation_generator.samples}\")\n",
        "    if test_generator:\n",
        "        print(f\"  Test samples: {test_generator.samples}\")\n",
        "    print(f\"  Classes: {train_generator.class_indices}\")\n",
        "    print(f\"  Image size: {IMG_SIZE}√ó{IMG_SIZE}\")\n",
        "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "# Create data generators with actual dataset structure\n",
        "train_gen, val_gen, test_gen = create_agricultural_data_generators(DATASET_PATH)\n",
        "\n",
        "if train_gen is not None:\n",
        "    print(\"\\n‚úÖ Data generators created successfully!\")\n",
        "    print(f\"üìä Ready to train on {NUM_CLASSES} pest categories\")\n",
        "\n",
        "    # Display a sample batch to verify everything works\n",
        "    print(\"\\nüñºÔ∏è Verifying data pipeline...\")\n",
        "    try:\n",
        "        sample_batch = next(iter(train_gen))\n",
        "        print(f\"Sample batch shape: {sample_batch[0].shape}\")\n",
        "        print(f\"Sample labels shape: {sample_batch[1].shape}\")\n",
        "        print(\"‚úÖ Data pipeline working correctly!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in data pipeline: {e}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Failed to create data generators. Please check dataset structure.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nLn83mPmJW8",
        "outputId": "5e2f6644-f786-49eb-8ed6-e7e8121f1822"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç EXPLORING ACTUAL DATASET STRUCTURE\n",
            "==================================================\n",
            "Found potential class directories:\n",
            "  - beetle\n",
            "  - grasshopper\n",
            "  - earthworms\n",
            "  - ants\n",
            "  - earwig\n",
            "  - snail\n",
            "  - catterpillar\n",
            "  - weevil\n",
            "  - bees\n",
            "  - moth\n",
            "  - wasp\n",
            "  - slug\n",
            "\n",
            "Classes found: 12\n",
            "  - beetle: 416 images\n",
            "  - grasshopper: 485 images\n",
            "  - earthworms: 323 images\n",
            "  - ants: 499 images\n",
            "  - earwig: 466 images\n",
            "  - snail: 500 images\n",
            "  - catterpillar: 434 images\n",
            "  - weevil: 485 images\n",
            "  - bees: 500 images\n",
            "  - moth: 497 images\n",
            "  - wasp: 498 images\n",
            "  - slug: 391 images\n",
            "üåæ AGRICULTURAL DATA GENERATORS SETUP\n",
            "==================================================\n",
            "üìÅ Main dataset directory: /kaggle/input/agricultural-pests-image-dataset\n",
            "üè∑Ô∏è Classes: ['beetle', 'grasshopper', 'earthworms', 'ants', 'earwig', 'snail', 'catterpillar', 'weevil', 'bees', 'moth', 'wasp', 'slug']\n",
            "üìä Number of classes: 12\n",
            "üìê Using validation_split=0.2 from main directory.\n",
            "Found 4399 images belonging to 12 classes.\n",
            "Found 1095 images belonging to 12 classes.\n",
            "\n",
            "üìà DATA GENERATOR SUMMARY:\n",
            "  Training samples: 4399\n",
            "  Validation samples: 1095\n",
            "  Classes: {'ants': 0, 'bees': 1, 'beetle': 2, 'catterpillar': 3, 'earthworms': 4, 'earwig': 5, 'grasshopper': 6, 'moth': 7, 'slug': 8, 'snail': 9, 'wasp': 10, 'weevil': 11}\n",
            "  Image size: 224√ó224\n",
            "  Batch size: 32\n",
            "\n",
            "‚úÖ Data generators created successfully!\n",
            "üìä Ready to train on 12 pest categories\n",
            "\n",
            "üñºÔ∏è Verifying data pipeline...\n",
            "Sample batch shape: (32, 224, 224, 3)\n",
            "Sample labels shape: (32, 12)\n",
            "‚úÖ Data pipeline working correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Configure EfficientNetV2 for Agricultural Pest Classification"
      ],
      "metadata": {
        "id": "8PlaWPzXqIXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_agricultural_pest_model(input_shape=(224, 224, 3),\n",
        "                                   num_classes=None,\n",
        "                                   model_variant='B0'):\n",
        "    \"\"\"\n",
        "    Create EfficientNetV2 model optimized for agricultural pest classification\n",
        "\n",
        "    Args:\n",
        "        input_shape: Input image dimensions\n",
        "        num_classes: Number of pest categories (automatically detected from dataset)\n",
        "        model_variant: EfficientNetV2 variant ('B0', 'B1', 'B3')\n",
        "    \"\"\"\n",
        "\n",
        "    # Use detected number of classes if not specified\n",
        "    if num_classes is None:\n",
        "        num_classes = NUM_CLASSES\n",
        "\n",
        "    print(f\"üåæ CREATING AGRICULTURAL PEST MODEL\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"üè∑Ô∏è Number of classes: {num_classes}\")\n",
        "\n",
        "    # Select EfficientNetV2 variant based on deployment needs\n",
        "    if model_variant == 'B0':\n",
        "        base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        print(\"üöÄ Using EfficientNetV2-B0 (optimal for edge deployment)\")\n",
        "    elif model_variant == 'B1':\n",
        "        base_model = EfficientNetV2B1(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "        print(\"üöÄ Using EfficientNetV2-B1 (balanced performance)\")\n",
        "    else:\n",
        "        print(\"üöÄ Defaulting to EfficientNetV2-B0\")\n",
        "        base_model = EfficientNetV2B0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze base model for initial transfer learning\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Agricultural-specific classification head\n",
        "    inputs = base_model.input\n",
        "    x = base_model(inputs, training=False)\n",
        "\n",
        "    # Global average pooling - better than flatten for varying pest sizes\n",
        "    x = GlobalAveragePooling2D(name='global_avg_pooling')(x)\n",
        "\n",
        "    # Agricultural domain adaptation layers\n",
        "    x = Dense(256, activation='relu', name='agricultural_features')(x)\n",
        "    x = BatchNormalization(name='ag_batch_norm')(x)\n",
        "    x = Dropout(0.3, name='ag_dropout_1')(x)\n",
        "\n",
        "    # Pest-specific feature layer\n",
        "    x = Dense(128, activation='relu', name='pest_features')(x)\n",
        "    x = Dropout(0.2, name='ag_dropout_2')(x)\n",
        "\n",
        "    # Final classification layer\n",
        "    if num_classes == 2:\n",
        "        # Binary classification (pest vs beneficial)\n",
        "        outputs = Dense(1, activation='sigmoid', name='pest_classification')(x)\n",
        "        loss = 'binary_crossentropy'\n",
        "    else:\n",
        "        # Multi-class classification\n",
        "        outputs = Dense(num_classes, activation='softmax', name='pest_classification')(x)\n",
        "        loss = 'categorical_crossentropy'\n",
        "\n",
        "    model = Model(inputs, outputs, name='agricultural_pest_classifier')\n",
        "\n",
        "    return model, base_model, loss\n",
        "\n",
        "# Only create model if we have data generators\n",
        "if 'train_gen' in locals() and train_gen is not None:\n",
        "    # Create agricultural pest management model\n",
        "    pest_model, base_model, loss_function = create_agricultural_pest_model(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        num_classes=NUM_CLASSES,\n",
        "        model_variant='B0'  # Use B0 for efficient farm deployment\n",
        "    )\n",
        "\n",
        "    print(f\"\\nüìä MODEL STATISTICS:\")\n",
        "    print(f\"  Base model parameters: {base_model.count_params():,}\")\n",
        "    print(f\"  Total model parameters: {pest_model.count_params():,}\")\n",
        "    print(f\"  Custom agricultural layers: {pest_model.count_params() - base_model.count_params():,}\")\n",
        "    print(f\"  Loss function: {loss_function}\")\n",
        "\n",
        "    # Display model architecture\n",
        "    print(f\"\\nüèóÔ∏è MODEL ARCHITECTURE:\")\n",
        "    pest_model.summary()\n",
        "\n",
        "    print(f\"\\nüìã MODEL FEATURES FOR AGRICULTURE:\")\n",
        "    print(\"‚úÖ Transfer learning from ImageNet (includes insects/animals)\")\n",
        "    print(\"‚úÖ Optimized for fine-grained pest classification\")\n",
        "    print(\"‚úÖ Efficient architecture for farm edge computing\")\n",
        "    print(\"‚úÖ Robust to outdoor lighting variations\")\n",
        "    print(\"‚úÖ Handles variable pest sizes and orientations\")\n",
        "    print(f\"‚úÖ Configured for {NUM_CLASSES} pest categories\")\n",
        "\n",
        "    # Compile the model\n",
        "    pest_model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss=loss_function,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"\\n‚úÖ Model compiled and ready for training!\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot create model - data generators not available\")\n",
        "    print(\"Please run the previous cell to set up data generators first\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "z1JJ8703pzrC",
        "outputId": "4e7c5fbc-2b83-43fa-b8c5-183188876e34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåæ CREATING AGRICULTURAL PEST MODEL\n",
            "==================================================\n",
            "üè∑Ô∏è Number of classes: 12\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "\u001b[1m24274472/24274472\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "üöÄ Using EfficientNetV2-B0 (optimal for edge deployment)\n",
            "\n",
            "üìä MODEL STATISTICS:\n",
            "  Base model parameters: 5,919,312\n",
            "  Total model parameters: 6,282,716\n",
            "  Custom agricultural layers: 363,404\n",
            "  Loss function: categorical_crossentropy\n",
            "\n",
            "üèóÔ∏è MODEL ARCHITECTURE:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"agricultural_pest_classifier\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"agricultural_pest_classifier\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ efficientnetv2-b0 (\u001b[38;5;33mFunctional\u001b[0m)  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     ‚îÇ     \u001b[38;5;34m5,919,312\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ global_avg_pooling              ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ agricultural_features (\u001b[38;5;33mDense\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ       \u001b[38;5;34m327,936\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ ag_batch_norm                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ         \u001b[38;5;34m1,024\u001b[0m ‚îÇ\n",
              "‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ ag_dropout_1 (\u001b[38;5;33mDropout\u001b[0m)          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ pest_features (\u001b[38;5;33mDense\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ        \u001b[38;5;34m32,896\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ ag_dropout_2 (\u001b[38;5;33mDropout\u001b[0m)          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ pest_classification (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             ‚îÇ         \u001b[38;5;34m1,548\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ efficientnetv2-b0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,312</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ global_avg_pooling              ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ agricultural_features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ ag_batch_norm                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> ‚îÇ\n",
              "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            ‚îÇ                        ‚îÇ               ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ ag_dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ pest_features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ ag_dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ pest_classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,282,716\u001b[0m (23.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,282,716</span> (23.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m362,892\u001b[0m (1.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">362,892</span> (1.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,919,824\u001b[0m (22.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,919,824</span> (22.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã MODEL FEATURES FOR AGRICULTURE:\n",
            "‚úÖ Transfer learning from ImageNet (includes insects/animals)\n",
            "‚úÖ Optimized for fine-grained pest classification\n",
            "‚úÖ Efficient architecture for farm edge computing\n",
            "‚úÖ Robust to outdoor lighting variations\n",
            "‚úÖ Handles variable pest sizes and orientations\n",
            "‚úÖ Configured for 12 pest categories\n",
            "\n",
            "‚úÖ Model compiled and ready for training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training Strategy for Agricultural Pest Management\n",
        "\n",
        "### Two-Phase Agricultural Training:\n",
        "\n",
        "**Phase 1: Agricultural Domain Adaptation (Frozen Base)**\n",
        "- Learn to map EfficientNetV2 features to agricultural pest categories\n",
        "- Fast training (only custom layers learn)\n",
        "- Preserve ImageNet insect/animal knowledge\n",
        "\n",
        "**Phase 2: Fine-tuning for Specific Farm Conditions**\n",
        "- Adapt EfficientNetV2 features for specific pest species\n",
        "- Learn farm-specific visual patterns\n",
        "- Handle local lighting/background conditions"
      ],
      "metadata": {
        "id": "TTXenvP7qboW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_agricultural_pest_model(model, base_model, train_gen, val_gen, loss_function):\n",
        "    \"\"\"\n",
        "    Two-phase training strategy for agricultural pest management\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üöú PHASE 1: AGRICULTURAL DOMAIN ADAPTATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Phase 1: Freeze EfficientNetV2, train agricultural layers\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss=loss_function,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Agricultural-specific callbacks (adjusted for Colab)\n",
        "    callbacks_phase1 = [\n",
        "        ModelCheckpoint(\n",
        "            '/content/agricultural_pest_model_phase1.h5',  # Colab path\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=3,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train Phase 1 (agricultural adaptation)\n",
        "    print(\"üå± Training agricultural domain adaptation...\")\n",
        "    history_phase1 = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=15,\n",
        "        callbacks=callbacks_phase1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\nüå± PHASE 2: FINE-TUNING FOR FARM CONDITIONS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Phase 2: Unfreeze and fine-tune for specific farm conditions\n",
        "    base_model.trainable = True\n",
        "\n",
        "    # Lower learning rate for fine-tuning\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),  # 10x lower\n",
        "        loss=loss_function,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    callbacks_phase2 = [\n",
        "        ModelCheckpoint(\n",
        "            '/content/agricultural_pest_model_final.h5',  # Colab path\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=8,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.3,\n",
        "            patience=4,\n",
        "            min_lr=1e-8,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train Phase 2 (fine-tuning)\n",
        "    print(\"üîß Fine-tuning for specific farm conditions...\")\n",
        "    history_phase2 = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=20,\n",
        "        callbacks=callbacks_phase2,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history_phase1, history_phase2\n",
        "\n",
        "def plot_training_history(history_phase1, history_phase2):\n",
        "    \"\"\"\n",
        "    Plot training history for both phases\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Phase 1 plots\n",
        "    axes[0, 0].plot(history_phase1.history['accuracy'], label='Training Accuracy')\n",
        "    axes[0, 0].plot(history_phase1.history['val_accuracy'], label='Validation Accuracy')\n",
        "    axes[0, 0].set_title('Phase 1: Domain Adaptation - Accuracy')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    axes[0, 1].plot(history_phase1.history['loss'], label='Training Loss')\n",
        "    axes[0, 1].plot(history_phase1.history['val_loss'], label='Validation Loss')\n",
        "    axes[0, 1].set_title('Phase 1: Domain Adaptation - Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "\n",
        "    # Phase 2 plots\n",
        "    axes[1, 0].plot(history_phase2.history['accuracy'], label='Training Accuracy')\n",
        "    axes[1, 0].plot(history_phase2.history['val_accuracy'], label='Validation Accuracy')\n",
        "    axes[1, 0].set_title('Phase 2: Fine-tuning - Accuracy')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Accuracy')\n",
        "    axes[1, 0].legend()\n",
        "\n",
        "    axes[1, 1].plot(history_phase2.history['loss'], label='Training Loss')\n",
        "    axes[1, 1].plot(history_phase2.history['val_loss'], label='Validation Loss')\n",
        "    axes[1, 1].set_title('Phase 2: Fine-tuning - Loss')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Loss')\n",
        "    axes[1, 1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Start training if model and data are ready\n",
        "if 'pest_model' in locals() and 'train_gen' in locals() and train_gen is not None:\n",
        "    print(\"üéØ READY TO START TRAINING!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Phase 1: Agricultural domain adaptation (15 epochs)\")\n",
        "    print(\"Phase 2: Farm-specific fine-tuning (20 epochs)\")\n",
        "    print(\"\\nTo start training, run the following:\")\n",
        "    print(\"trained_model, hist1, hist2 = train_agricultural_pest_model(pest_model, base_model, train_gen, val_gen, loss_function)\")\n",
        "    print(\"plot_training_history(hist1, hist2)\")\n",
        "\n",
        "    print(f\"\\nüìä Expected results for {NUM_CLASSES} classes:\")\n",
        "    print(\"- 85%+ accuracy on pest classification\")\n",
        "    print(\"- Robust performance in field conditions\")\n",
        "    print(\"- Good generalization to new pest images\")\n",
        "\n",
        "    print(f\"\\nüíæ Models will be saved to:\")\n",
        "    print(\"- /content/agricultural_pest_model_phase1.h5\")\n",
        "    print(\"- /content/agricultural_pest_model_final.h5\")\n",
        "\n",
        "    # Quick training setup verification\n",
        "    print(f\"\\nÔøΩ TRAINING SETUP VERIFICATION:\")\n",
        "    print(f\"  Training samples: {train_gen.samples}\")\n",
        "    print(f\"  Validation samples: {val_gen.samples}\")\n",
        "    print(f\"  Steps per epoch: {train_gen.samples // BATCH_SIZE}\")\n",
        "    print(f\"  Validation steps: {val_gen.samples // BATCH_SIZE}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot start training - model or data generators not ready\")\n",
        "    print(\"Please run previous cells to set up model and data first\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFS0PTqzqdV2",
        "outputId": "06b91345-3246-4796-8190-23770a4f8506"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ READY TO START TRAINING!\n",
            "==================================================\n",
            "Phase 1: Agricultural domain adaptation (15 epochs)\n",
            "Phase 2: Farm-specific fine-tuning (20 epochs)\n",
            "\n",
            "To start training, run the following:\n",
            "trained_model, hist1, hist2 = train_agricultural_pest_model(pest_model, base_model, train_gen, val_gen, loss_function)\n",
            "plot_training_history(hist1, hist2)\n",
            "\n",
            "üìä Expected results for 12 classes:\n",
            "- 85%+ accuracy on pest classification\n",
            "- Robust performance in field conditions\n",
            "- Good generalization to new pest images\n",
            "\n",
            "üíæ Models will be saved to:\n",
            "- /content/agricultural_pest_model_phase1.h5\n",
            "- /content/agricultural_pest_model_final.h5\n",
            "\n",
            "ÔøΩ TRAINING SETUP VERIFICATION:\n",
            "  Training samples: 4399\n",
            "  Validation samples: 1095\n",
            "  Steps per epoch: 137\n",
            "  Validation steps: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Agricultural Pest Prediction and Farm Deployment\n"
      ],
      "metadata": {
        "id": "Q7uc5nV_qpPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_pest_from_image(model, image_path, class_names):\n",
        "    \"\"\"\n",
        "    Predict pest type from farm image\n",
        "    \"\"\"\n",
        "    # Load and preprocess image\n",
        "    image = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "    image_array = img_to_array(image)\n",
        "    image_array = np.expand_dims(image_array, axis=0)\n",
        "    image_array = preprocess_input(image_array)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(image_array, verbose=0)\n",
        "\n",
        "    if len(class_names) == 2:\n",
        "        # Binary classification\n",
        "        confidence = predictions[0][0]\n",
        "        predicted_class = class_names[1] if confidence > 0.5 else class_names[0]\n",
        "        confidence = confidence if confidence > 0.5 else 1 - confidence\n",
        "    else:\n",
        "        # Multi-class classification\n",
        "        predicted_class_idx = np.argmax(predictions[0])\n",
        "        predicted_class = class_names[predicted_class_idx]\n",
        "        confidence = predictions[0][predicted_class_idx]\n",
        "\n",
        "    return predicted_class, confidence, predictions[0]\n",
        "\n",
        "def evaluate_model_on_test_set(model, test_gen):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation on test set\n",
        "    \"\"\"\n",
        "    if test_gen is None:\n",
        "        print(\"‚ùå No test generator available\")\n",
        "        return\n",
        "\n",
        "    print(\"üîç EVALUATING MODEL ON TEST SET\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Get predictions\n",
        "    test_gen.reset()\n",
        "    predictions = model.predict(test_gen, verbose=1)\n",
        "    y_pred = np.argmax(predictions, axis=1)\n",
        "    y_true = test_gen.classes\n",
        "\n",
        "    # Get class names\n",
        "    class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nüìä CLASSIFICATION REPORT:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "               xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Agricultural Pest Classification Results')\n",
        "    plt.ylabel('True Pest Type')\n",
        "    plt.xlabel('Predicted Pest Type')\n",
        "    plt.show()\n",
        "\n",
        "    # Per-class accuracy\n",
        "    print(\"\\nüéØ PER-CLASS ACCURACY:\")\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        class_accuracy = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
        "        print(f\"  {class_name}: {class_accuracy:.3f} ({class_accuracy*100:.1f}%)\")\n",
        "\n",
        "    return predictions, y_pred, y_true\n",
        "\n",
        "def visualize_sample_predictions(model, test_gen, num_samples=8):\n",
        "    \"\"\"\n",
        "    Visualize sample predictions\n",
        "    \"\"\"\n",
        "    if test_gen is None:\n",
        "        print(\"‚ùå No test generator available for visualization\")\n",
        "        return\n",
        "\n",
        "    # Get a batch of test images\n",
        "    test_gen.reset()\n",
        "    images, labels = next(test_gen)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(images[:num_samples], verbose=0)\n",
        "\n",
        "    # Get class names\n",
        "    class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "    # Plot images with predictions\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        # Denormalize image for display\n",
        "        img = images[i]\n",
        "        img = (img + 1) / 2  # Rough denormalization\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        # Get prediction\n",
        "        pred_class_idx = np.argmax(predictions[i])\n",
        "        true_class_idx = np.argmax(labels[i])\n",
        "\n",
        "        pred_class = class_names[pred_class_idx]\n",
        "        true_class = class_names[true_class_idx]\n",
        "        confidence = predictions[i][pred_class_idx]\n",
        "\n",
        "        # Plot\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "        # Color: green if correct, red if incorrect\n",
        "        color = 'green' if pred_class == true_class else 'red'\n",
        "        title = f'True: {true_class}\\nPred: {pred_class}\\n({confidence:.2f})'\n",
        "        axes[i].set_title(title, color=color, fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Sample Predictions on Test Set', fontsize=16, y=1.02)\n",
        "    plt.show()\n",
        "\n",
        "# Example usage and setup\n",
        "if 'train_gen' in locals() and train_gen is not None:\n",
        "    # Get class names from the actual dataset\n",
        "    class_names = list(train_gen.class_indices.keys())\n",
        "    print(\"üè∑Ô∏è DETECTED PEST CLASSES:\")\n",
        "    print(\"=\" * 30)\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        print(f\"  {i}: {class_name}\")\n",
        "\n",
        "    print(f\"\\nüìä PREDICTION SETUP:\")\n",
        "    print(f\"  Number of classes: {len(class_names)}\")\n",
        "    print(f\"  Classes: {class_names}\")\n",
        "\n",
        "    if 'pest_model' in locals():\n",
        "        print(\"\\n‚úÖ Ready for predictions!\")\n",
        "        print(\"\\nTo evaluate trained model:\")\n",
        "        print(\"predictions, y_pred, y_true = evaluate_model_on_test_set(trained_model, test_gen)\")\n",
        "        print(\"visualize_sample_predictions(trained_model, test_gen)\")\n",
        "\n",
        "        print(\"\\nTo predict on single image:\")\n",
        "        print(\"pred_class, confidence, probs = predict_pest_from_image(trained_model, 'path/to/image.jpg', class_names)\")\n",
        "\n",
        "    # Agricultural impact assessment\n",
        "    print(f\"\\nÔøΩ AGRICULTURAL IMPACT POTENTIAL:\")\n",
        "    print(\"=\" * 40)\n",
        "    if 'beneficial' in [c.lower() for c in class_names] and 'harmful' in [c.lower() for c in class_names]:\n",
        "        print(\"‚úÖ Beneficial vs Harmful classification detected\")\n",
        "        print(\"‚úÖ Can support organic farming practices\")\n",
        "        print(\"‚úÖ Enables targeted pest management\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è  Pest species classification detected\")\n",
        "        print(\"‚ÑπÔ∏è  Can enable species-specific management\")\n",
        "\n",
        "    print(f\"‚úÖ Model can distinguish between {len(class_names)} pest categories\")\n",
        "    print(\"‚úÖ Suitable for field deployment and monitoring\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot set up predictions - data generators not available\")\n",
        "    print(\"Please run previous cells to set up the dataset first\")"
      ],
      "metadata": {
        "id": "m5aGcdOuqp--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "819de4dc-8226-45ac-eb4a-d86f1cbdde50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üè∑Ô∏è DETECTED PEST CLASSES:\n",
            "==============================\n",
            "  0: ants\n",
            "  1: bees\n",
            "  2: beetle\n",
            "  3: catterpillar\n",
            "  4: earthworms\n",
            "  5: earwig\n",
            "  6: grasshopper\n",
            "  7: moth\n",
            "  8: slug\n",
            "  9: snail\n",
            "  10: wasp\n",
            "  11: weevil\n",
            "\n",
            "üìä PREDICTION SETUP:\n",
            "  Number of classes: 12\n",
            "  Classes: ['ants', 'bees', 'beetle', 'catterpillar', 'earthworms', 'earwig', 'grasshopper', 'moth', 'slug', 'snail', 'wasp', 'weevil']\n",
            "\n",
            "‚úÖ Ready for predictions!\n",
            "\n",
            "To evaluate trained model:\n",
            "predictions, y_pred, y_true = evaluate_model_on_test_set(trained_model, test_gen)\n",
            "visualize_sample_predictions(trained_model, test_gen)\n",
            "\n",
            "To predict on single image:\n",
            "pred_class, confidence, probs = predict_pest_from_image(trained_model, 'path/to/image.jpg', class_names)\n",
            "\n",
            "ÔøΩ AGRICULTURAL IMPACT POTENTIAL:\n",
            "========================================\n",
            "‚ÑπÔ∏è  Pest species classification detected\n",
            "‚ÑπÔ∏è  Can enable species-specific management\n",
            "‚úÖ Model can distinguish between 12 pest categories\n",
            "‚úÖ Suitable for field deployment and monitoring\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uKtTCdfTX2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}